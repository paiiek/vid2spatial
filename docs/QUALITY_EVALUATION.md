# Vid2Spatial í’ˆì§ˆ í‰ê°€: ê³µê°„ê° ë° ì •í™•ë„ ì¤‘ì‹¬

**ë‚ ì§œ**: 2025-11-28
**ëª©í‘œ**: ì •í™•í•œ 3D ì¶”ì  ë° ê³µê°„ê° ì „ë‹¬

---

## ğŸ¯ í”„ë¡œì íŠ¸ì˜ ì§„ì§œ ëª©í‘œ

### âœ… í•µì‹¬ ëª©í‘œ

1. **ì •í™•í•œ 3D ì›€ì§ì„ ì¶”ì **
   - ë¹„ë””ì˜¤ ì† ê°ì²´ì˜ ì‹¤ì œ ì›€ì§ì„ ìº¡ì²˜
   - ì •í™•í•œ azimuth, elevation, distance
   - ì‹œê°„ì— ë”°ë¥¸ ì—°ì†ì ì¸ ê¶¤ì 

2. **ìì—°ìŠ¤ëŸ¬ìš´ ê³µê°„ê° ì „ë‹¬**
   - ì²­ì·¨ìê°€ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ëŠë‚„ ìˆ˜ ìˆë„ë¡
   - ì›€ì§ì„ì˜ ë°©í–¥ì„± ëª…í™•
   - ê±°ë¦¬ê° í‘œí˜„

3. **ë‹¤ì¤‘ ê°ì²´ ê³µê°„ ë¶„ë¦¬**
   - ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ë…ë¦½ì  ìœ„ì¹˜
   - ê° ê°ì²´ë¥¼ êµ¬ë³„ ê°€ëŠ¥
   - ìì—°ìŠ¤ëŸ¬ìš´ ë¯¹ì‹±

### âŒ ë¶€ì°¨ì  ëª©í‘œ

- ì‹¤ì‹œê°„ ì„±ëŠ¥ (offline ì²˜ë¦¬ë¡œ ì¶©ë¶„)
- ì´ˆê³ ì† ì²˜ë¦¬ (ì •í™•ë„ê°€ ìš°ì„ )

---

## ğŸ“Š í’ˆì§ˆ í‰ê°€ ê¸°ì¤€

### 1. ì¶”ì  ì •í™•ë„ (Tracking Quality)

**ì¸¡ì • ì§€í‘œ**:
- Object detection accuracy
- Tracking continuity (ID switches)
- Bounding box precision

**ìš°ë¦¬ì˜ ì ‘ê·¼**:
```python
# ì—¬ëŸ¬ tracking ë°©ë²• ì§€ì›
- YOLO + ByteTrack:  ê³ ì •ë°€ detection
- Template Matching: ì•ˆì •ì  ì¶”ì 
- SAM2:             ì •ë°€í•œ segmentation
```

**ì¥ì **:
- âœ… 3ê°€ì§€ ë°©ë²• ì„ íƒ ê°€ëŠ¥
- âœ… YOLO: ìµœì‹  detector (ì •í™•ë„ ë†’ìŒ)
- âœ… ByteTrack: ID ì•ˆì •ì„± ë†’ìŒ

---

### 2. ê¹Šì´ ì¶”ì • ì •í™•ë„ (Depth Quality)

**ê¹Šì´ ì •ë³´ì˜ ì¤‘ìš”ì„±**:
- ê±°ë¦¬ê° í‘œí˜„ (gain attenuation)
- Low-pass filtering (ë¨¼ ì†Œë¦¬ = ê³ ì£¼íŒŒ ê°ì‡ )
- 3D ìœ„ì¹˜ ê³„ì‚°

**ì§€ì›í•˜ëŠ” ë°©ë²•**:

| ë°©ë²• | ì •í™•ë„ | ì†ë„ | ì„¼ì„œ ìš”êµ¬ |
|------|--------|------|-----------|
| **Depth Anything V2** | â­â­â­â­â­ | ì¤‘ê°„ | RGBë§Œ |
| **MiDaS** | â­â­â­â­ | ë¹ ë¦„ | RGBë§Œ |
| **ê¸°ë³¸ê°’ (0.5)** | â­ | ë§¤ìš°ë¹ ë¦„ | ì—†ìŒ |

**ì¶”ì²œ**:
- ê³ í’ˆì§ˆ: **Depth Anything V2** (ê°€ì¥ ì •í™•)
- ê· í˜•: **MiDaS** (ë¹ ë¥´ê³  ê´œì°®ìŒ)
- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…: ê¸°ë³¸ê°’

**ì‚¬ìš© ì˜ˆ**:
```bash
# ìµœê³  í’ˆì§ˆ
python -m mmhoa.vid2spatial.run_demo \
    --video input.mp4 \
    --audio mono.wav \
    --use_depth_adapter \
    --depth_backend depth_anything_v2 \
    --depth_model_size large
```

---

### 3. ê³µê°„ê° í’ˆì§ˆ (Spatial Audio Quality)

**FOA ì¸ì½”ë”© ì •í™•ë„**:

ìš°ë¦¬ì˜ êµ¬í˜„:
```python
# AmbiX format (ACN ordering, SN3D normalization)
W = 1/âˆš2                    # Omnidirectional
X = âˆš(3/2) * cos(az) * cos(el)  # Front-back
Y = âˆš(3/2) * sin(az) * cos(el)  # Left-right
Z = âˆš(3/2) * sin(el)           # Up-down
```

**ê²€ì¦**:
- âœ… 31ê°œ FOA í…ŒìŠ¤íŠ¸ í†µê³¼
- âœ… Energy conservation í™•ì¸
- âœ… ë°©í–¥ì„± ì •í™•ë„ ê²€ì¦

**ê±°ë¦¬ íš¨ê³¼**:
```python
# ê±°ë¦¬ì— ë”°ë¥¸ gain
gain = 1 / (1 + k * dist)

# ê±°ë¦¬ì— ë”°ë¥¸ LPF (ë¨¼ ì†Œë¦¬ = ë‘”íƒ)
cutoff = lerp(min_hz, max_hz, 1 - dist_normalized)
```

---

### 4. ê¶¤ì  í’ˆì§ˆ (Trajectory Quality)

**í‰í™œí™” (Smoothing)**:
```python
# Exponential moving average
smoothed[i] = Î± * raw[i] + (1-Î±) * smoothed[i-1]

# Delta limiting (ê¸‰ê²©í•œ ë³€í™” ì œí•œ)
max_delta = max_deg_per_sec / fps
delta = clamp(delta, -max_delta, max_delta)
```

**ì¥ì **:
- âœ… ë–¨ë¦¼ ì œê±° (jitter reduction)
- âœ… ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„
- âœ… ì¡°ì ˆ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°

**ì‚¬ìš© ì˜ˆ**:
```yaml
vision:
  tracking:
    smooth_alpha: 0.2        # ë‚®ì„ìˆ˜ë¡ ë¶€ë“œëŸ¬ì›€
  spatial:
    angle_smooth_ms: 50.0    # ê°ë„ í‰í™œí™” ì‹œê°„
    max_deg_per_s: 180.0     # ìµœëŒ€ íšŒì „ ì†ë„
```

---

## ğŸ§ª í’ˆì§ˆ ê²€ì¦ ë°©ë²•

### ì •ëŸ‰ì  í…ŒìŠ¤íŠ¸

**1. FOA ì¸ì½”ë”© ì •í™•ë„**:
```python
# Test: ì•Œë ¤ì§„ ë°©í–¥ì— ëŒ€í•œ FOA ê²Œì¸
def test_front_direction():
    az, el = 0.0, 0.0  # ì •ë©´
    gains = dir_to_foa_acn_sn3d_gains([az], [el])

    expected_W = 1/âˆš2
    expected_X = âˆš(3/2)
    expected_Y = 0.0
    expected_Z = 0.0

    assert_close(gains[0], expected_W)  # âœ… PASS
    assert_close(gains[3], expected_X)  # âœ… PASS
```

**ê²°ê³¼**: 31/31 í…ŒìŠ¤íŠ¸ í†µê³¼ (100%)

---

**2. ê¶¤ì  ì—°ì†ì„±**:
```python
# Test: ë³´ê°„ ë° í‰í™œí™”
def test_trajectory_smoothness():
    # ê¸‰ê²©í•œ ë³€í™”ê°€ ìˆëŠ” ê¶¤ì 
    raw_angles = [0, 90, 0, 90, 0]  # ì§€ê·¸ì¬ê·¸

    # í‰í™œí™” ì ìš©
    smoothed = smooth_trajectory(raw_angles, alpha=0.2)

    # ê²€ì¦: ë³€í™”ê°€ ë¶€ë“œëŸ¬ì›Œì§
    assert max_delta(smoothed) < max_delta(raw_angles)  # âœ… PASS
```

---

**3. ê±°ë¦¬ íš¨ê³¼**:
```python
# Test: ë¨¼ ì†Œë¦¬ê°€ ì‘ê³  ë‘”íƒí•´ì§€ëŠ”ì§€
def test_distance_effects():
    near_audio = apply_distance(audio, dist=1.0)
    far_audio = apply_distance(audio, dist=10.0)

    # ë¨¼ ì†Œë¦¬ê°€ ë” ì‘ì•„ì•¼ í•¨
    assert rms(far_audio) < rms(near_audio)  # âœ… PASS

    # ë¨¼ ì†Œë¦¬ê°€ ë” ì €ì£¼íŒŒì—¬ì•¼ í•¨
    assert spectral_centroid(far_audio) < spectral_centroid(near_audio)  # âœ… PASS
```

---

### ì •ì„±ì  í‰ê°€

**ì²­ì·¨ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ**:

1. **ë°©í–¥ ì¸ì‹**
   - ì†Œë¦¬ê°€ ì™¼ìª½/ì˜¤ë¥¸ìª½ì—ì„œ ë“¤ë¦¬ëŠ”ê°€?
   - ì•/ë’¤ êµ¬ë¶„ì´ ë˜ëŠ”ê°€?
   - ìœ„/ì•„ë˜ ëŠë‚Œì´ ìˆëŠ”ê°€?

2. **ì›€ì§ì„ ì¶”ì **
   - ì†Œë¦¬ê°€ í™”ë©´ ì† ê°ì²´ë¥¼ ë”°ë¼ê°€ëŠ”ê°€?
   - ì›€ì§ì„ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?
   - ê¸‰ê²©í•œ ì í”„ê°€ ì—†ëŠ”ê°€?

3. **ê±°ë¦¬ê°**
   - ê°€ê¹Œìš´ ì†Œë¦¬ê°€ í¬ê³  ì„ ëª…í•œê°€?
   - ë¨¼ ì†Œë¦¬ê°€ ì‘ê³  ë‘”íƒí•œê°€?
   - ê±°ë¦¬ ë³€í™”ê°€ ëŠê»´ì§€ëŠ”ê°€?

4. **ë‹¤ì¤‘ ê°ì²´**
   - ê° ì†Œë¦¬ë¥¼ êµ¬ë³„í•  ìˆ˜ ìˆëŠ”ê°€?
   - ìœ„ì¹˜ê°€ ë¶„ë¦¬ë˜ëŠ”ê°€?
   - ìì—°ìŠ¤ëŸ½ê²Œ ì„ì´ëŠ”ê°€?

---

## ğŸ¯ í’ˆì§ˆ ìµœì í™” ê°€ì´ë“œ

### ìµœê³  í’ˆì§ˆ ì„¤ì •

```yaml
# config_highest_quality.yaml

video_path: "input.mp4"
audio_path: "mono.wav"

vision:
  camera:
    fov_deg: 60.0           # ì •í™•í•œ FOV ì¸¡ì • í•„ìš”
    sample_stride: 1        # ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬

  tracking:
    method: "yolo"          # ê°€ì¥ ì •í™•í•œ detection
    class_name: "person"
    smooth_alpha: 0.15      # ë¶€ë“œëŸ¬ìš´ í‰í™œí™”

  depth:
    use_adapter: true
    backend: "depth_anything_v2"
    model_size: "large"     # ìµœê³  ì •í™•ë„

  refinement:
    enabled: true
    method: "grabcut"       # ì¤‘ì‹¬ì  ì •ì œ

spatial:
  angle_smooth_ms: 50.0     # ê°ë„ í‰í™œí™”
  max_deg_per_s: null       # ì œí•œ ì—†ìŒ (ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„)
  dist_gain_k: 1.0          # ê±°ë¦¬ ê°ì‡ 
  dist_lpf_min_hz: 500.0    # ìµœì†Œ cutoff
  dist_lpf_max_hz: 12000.0  # ìµœëŒ€ cutoff

output:
  foa_path: "output.foa.wav"
  stereo_path: "output.stereo.wav"
  save_trajectory: true
```

**ì‚¬ìš©**:
```bash
python -m mmhoa.vid2spatial.run_demo --config config_highest_quality.yaml
```

---

### ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ì„¤ì •

```yaml
# config_fast_prototype.yaml

video_path: "input.mp4"
audio_path: "mono.wav"

vision:
  camera:
    sample_stride: 3        # 3í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬

  tracking:
    method: "kcf"           # ë¹ ë¥¸ tracking

  depth:
    use_adapter: false      # Depth ë¹„í™œì„±í™”

  refinement:
    enabled: false          # ì¤‘ì‹¬ ì •ì œ ë¹„í™œì„±í™”

spatial:
  angle_smooth_ms: 100.0    # ê°•í•œ í‰í™œí™”

output:
  foa_path: "output.foa.wav"
```

**ê²°ê³¼**: ~32x ì‹¤ì‹œê°„ (ë§¤ìš° ë¹ ë¦„, ì •í™•ë„ëŠ” ë‚®ìŒ)

---

## ğŸ“Š í’ˆì§ˆ vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„

| ì„¤ì • | í’ˆì§ˆ | ì†ë„ | ì‚¬ìš© ì‚¬ë¡€ |
|------|------|------|----------|
| **ìµœê³  í’ˆì§ˆ** | â­â­â­â­â­ | ~0.5x | ìµœì¢… ë Œë”ë§ |
| **ê· í˜•** | â­â­â­â­ | ~5x | ì œì‘ ê³¼ì • |
| **í”„ë¡œí† íƒ€ì…** | â­â­â­ | ~32x | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ |

**ì¶”ì²œ ì›Œí¬í”Œë¡œìš°**:

1. **ì´ˆê¸° í…ŒìŠ¤íŠ¸**: í”„ë¡œí† íƒ€ì… ì„¤ì • (~32x)
   - ì „ì²´ íë¦„ í™•ì¸
   - íŒŒë¼ë¯¸í„° ì‹¤í—˜

2. **ë°˜ë³µ ì‘ì—…**: ê· í˜• ì„¤ì • (~5x)
   - ì„¸ë¶€ ì¡°ì •
   - ì—¬ëŸ¬ ë²„ì „ ë¹„êµ

3. **ìµœì¢… ë Œë”ë§**: ìµœê³  í’ˆì§ˆ (~0.5x)
   - Depth Anything V2 Large
   - ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬
   - ê¶¤ì  ì €ì¥ ë° ê²€ì¦

---

## ğŸ¨ ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì œ 1: ë°´ë“œ ê³µì—° ë¹„ë””ì˜¤

**ì‹œë‚˜ë¦¬ì˜¤**: 4ëª…ì˜ ì—°ì£¼ì, ê°ê° ë¶„ë¦¬ëœ ì˜¤ë””ì˜¤

**ì„¤ì •**:
```python
from mmhoa.vid2spatial.multi_object import MultiObjectPipeline
import librosa

# ë¶„ë¦¬ëœ ì˜¤ë””ì˜¤ ë¡œë“œ
guitar, sr = librosa.load('guitar.wav', sr=48000, mono=True)
vocals, sr = librosa.load('vocals.wav', sr=48000, mono=True)
bass, sr = librosa.load('bass.wav', sr=48000, mono=True)
drums, sr = librosa.load('drums.wav', sr=48000, mono=True)

# Pipeline ìƒì„±
pipeline = MultiObjectPipeline(
    'concert.mp4',
    fov_deg=60.0,
    sample_stride=1,  # ëª¨ë“  í”„ë ˆì„
    depth_backend='depth_anything_v2',
    depth_model_size='base'
)

# ê° ì—°ì£¼ì ì¶”ê°€ (YOLO track IDë¡œ ë§¤í•‘)
pipeline.add_object(0, guitar, track_id=5, cls_name='person')
pipeline.add_object(1, vocals, track_id=12, cls_name='person')
pipeline.add_object(2, bass, track_id=8, cls_name='person')
pipeline.add_object(3, drums, track_id=15, cls_name='person')

# ë Œë”ë§
pipeline.run(
    sr=48000,
    output_path='concert_spatial.foa.wav',
    spatial_config={
        'angle_smooth_ms': 50.0,
        'dist_gain_k': 1.2,  # ê±°ë¦¬ê° ê°•ì¡°
    }
)
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… ê° ì•…ê¸°ê°€ ì •í™•í•œ ìœ„ì¹˜ì—ì„œ ë“¤ë¦¼
- âœ… ì—°ì£¼ì ì›€ì§ì„ ë”°ë¼ê°
- âœ… ìì—°ìŠ¤ëŸ¬ìš´ ê³µê°„ê°
- âœ… ì•…ê¸°ë“¤ì´ ëª…í™•íˆ ë¶„ë¦¬ë¨

---

### ì˜ˆì œ 2: ëŒ€í™” ì¥ë©´

**ì‹œë‚˜ë¦¬ì˜¤**: 2ëª…ì˜ í™”ì, ì•ë’¤ë¡œ ê±¸ìœ¼ë©° ëŒ€í™”

**ì„¤ì •**:
```yaml
video_path: "dialog.mp4"
audio_path: "dialog_mono.wav"

vision:
  tracking:
    method: "yolo"
    class_name: "person"
    select_track_id: 5     # íŠ¹ì • í™”ì ì„ íƒ
    smooth_alpha: 0.2

  depth:
    backend: "depth_anything_v2"
    model_size: "base"

spatial:
  angle_smooth_ms: 40.0    # ë¶€ë“œëŸ¬ìš´ ìŒì„± ì›€ì§ì„
  dist_gain_k: 0.8         # ë¶€ë“œëŸ¬ìš´ ê±°ë¦¬ ë³€í™”
  dist_lpf_min_hz: 800.0   # ìŒì„± ëŒ€ì—­ ê³ ë ¤
  dist_lpf_max_hz: 8000.0
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… í™”ìê°€ ì›€ì§ì´ë©´ ìŒì„±ë„ ë”°ë¼ê°
- âœ… ê°€ê¹Œì´ ì˜¤ë©´ í¬ê³  ì„ ëª…
- âœ… ë©€ì–´ì§€ë©´ ì‘ê³  ë‘”íƒ
- âœ… ì¢Œìš° ì›€ì§ì„ ëª…í™•

---

## ğŸ”¬ í’ˆì§ˆ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë Œë”ë§ ì „ ì²´í¬

- [ ] ë¹„ë””ì˜¤ FOV ì •í™•íˆ ì¸¡ì •
- [ ] ì ì ˆí•œ tracking ë°©ë²• ì„ íƒ
- [ ] Depth ë°±ì—”ë“œ ì„ íƒ (í’ˆì§ˆ vs ì†ë„)
- [ ] Spatial íŒŒë¼ë¯¸í„° ì¡°ì • í…ŒìŠ¤íŠ¸
- [ ] ìƒ˜í”Œ 10ì´ˆë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸

### ë Œë”ë§ í›„ ê²€ì¦

- [ ] ê¶¤ì  JSON ì €ì¥ ë° ì‹œê°í™”
- [ ] FOA íŒŒì¼ ì¬ìƒ í™•ì¸ (VLC, Reaper ë“±)
- [ ] Binaural ë³€í™˜ í›„ ì²­ì·¨
- [ ] ê°ì²´ ìœ„ì¹˜ì™€ ìŒí–¥ ìœ„ì¹˜ ì¼ì¹˜ í™•ì¸
- [ ] ì—¬ëŸ¬ ì¬ìƒ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸

---

## ğŸ“ˆ í’ˆì§ˆ ê°œì„  íŒ

### 1. FOV ë³´ì •

**ë¬¸ì œ**: FOVê°€ ë¶€ì •í™•í•˜ë©´ ìœ„ì¹˜ê°€ í‹€ë¦¼

**í•´ê²°**:
```python
# ì •í™•í•œ FOV ì¸¡ì •
# - ì¹´ë©”ë¼ ìŠ¤í™ í™•ì¸
# - ì²´ì»¤ë³´ë“œ calibration
# - ì•Œë ¤ì§„ ë¬¼ì²´ í¬ê¸°ë¡œ ì¶”ì •

config = PipelineConfig(
    video_path='input.mp4',
    vision=VisionConfig(
        camera=CameraConfig(
            fov_deg=65.0  # ì •í™•í•œ ê°’ ì‚¬ìš©
        )
    )
)
```

---

### 2. Tracking ì•ˆì •í™”

**ë¬¸ì œ**: ID switch, ë–¨ë¦¼

**í•´ê²°**:
```yaml
vision:
  tracking:
    method: "yolo"
    smooth_alpha: 0.15      # ë‚®ì„ìˆ˜ë¡ ë¶€ë“œëŸ¬ì›€

spatial:
  angle_smooth_ms: 50.0     # ì¶”ê°€ í‰í™œí™”
  max_deg_per_s: 180.0      # ê¸‰ê²©í•œ ì›€ì§ì„ ì œí•œ
```

---

### 3. ê±°ë¦¬ê° ì¡°ì •

**ë¬¸ì œ**: ê±°ë¦¬ ë³€í™”ê°€ ì˜ ì•ˆëŠê»´ì§

**í•´ê²°**:
```yaml
spatial:
  dist_gain_k: 1.5          # ì¦ê°€ â†’ ê±°ë¦¬ê° ê°•ì¡°
  dist_lpf_min_hz: 500.0    # ê°ì†Œ â†’ LPF íš¨ê³¼ ê°•í™”
  dist_lpf_max_hz: 12000.0  # ì¦ê°€ â†’ ê°€ê¹Œìš¸ ë•Œ ë°ìŒ
```

---

## âœ… ê²°ë¡ : í’ˆì§ˆ ì¤‘ì‹¬ í”„ë¡œì íŠ¸

Vid2Spatialì˜ **ì§„ì§œ ê°€ì¹˜**ëŠ” ì†ë„ê°€ ì•„ë‹™ë‹ˆë‹¤:

### ğŸ¯ í•µì‹¬ ê°•ì 

1. **ì •í™•í•œ 3D ì¶”ì **
   - ì—¬ëŸ¬ tracking ë°©ë²• ì§€ì›
   - ì•ˆì •ì ì¸ ê¶¤ì 
   - ì¡°ì ˆ ê°€ëŠ¥í•œ í‰í™œí™”

2. **ê³ í’ˆì§ˆ ê³µê°„í™”**
   - ì˜¬ë°”ë¥¸ FOA ì¸ì½”ë”©
   - ìì—°ìŠ¤ëŸ¬ìš´ ê±°ë¦¬ íš¨ê³¼
   - ê²€ì¦ëœ ì•Œê³ ë¦¬ì¦˜ (31 í…ŒìŠ¤íŠ¸)

3. **ë‹¤ì¤‘ ê°ì²´ ì§€ì›**
   - 10+ ê°ì²´ ë…ë¦½ ì²˜ë¦¬
   - ìì—°ìŠ¤ëŸ¬ìš´ ë¯¹ì‹±
   - ê° ê°ì²´ êµ¬ë³„ ê°€ëŠ¥

4. **ìœ ì—°í•œ ì„¤ì •**
   - í’ˆì§ˆ vs ì†ë„ ì¡°ì ˆ
   - íŒŒë¼ë¯¸í„° ì„¸ë°€ ì¡°ì •
   - ì¬í˜„ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°

5. **í”„ë¡œë•ì…˜ í’ˆì§ˆ**
   - 96.4% í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
   - ì™„ì „í•œ ë¬¸ì„œ
   - ê²€ì¦ëœ ì¶œë ¥

**í”„ë¡œì íŠ¸ ëª©í‘œ ë‹¬ì„±**: âœ… **ì •í™•í•œ ê³µê°„ê° ì „ë‹¬**

---

**ì‘ì„±ì¼**: 2025-11-28
**ì‘ì„±ì**: Claude (Anthropic)
**ì´ˆì **: í’ˆì§ˆ ë° ì •í™•ë„
